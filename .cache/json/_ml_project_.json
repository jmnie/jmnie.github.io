{"data":{"site":{"siteMetadata":{"title":"Jiaming's Nutshell"}},"markdownRemark":{"id":"763e395a-0ff2-5606-a25f-c5a9059fc6ac","excerpt":"This is the webpage of WPI CS 539 (Machine Learning) final project. Group Member: Jiaming Nie, Ruojun Li, Yu Li, Yang Tao, Guangda Li Introduction To Styleâ€¦","html":"<p>This is the webpage of WPI CS 539 (Machine Learning) final project.</p>\n<p>Group Member:</p>\n<p>Jiaming Nie, Ruojun Li, Yu Li, Yang Tao, Guangda Li</p>\n<h1>Introduction To Style Transfer</h1>\n<p>Style transfer is the technique of recomposing images in the style of other images. Three images will be taken, a content image, a style image and output image.</p>\n<p>Deep convolutional neural network is a powerful tool to extract the feature which represents the styles. The style could be the structure of one painting, the way artists draw their paintings and the colors that the artists use. Representation of content images can also be extracted using the deep convolutional neural network.</p>\n<p>A style transfer demo is illustrated on the following image:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/d068b09179d2fac329ed722c8820855c/c58a3/uol_output.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 62.16216216216216%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAMABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAQBAgP/xAAWAQEBAQAAAAAAAAAAAAAAAAADAAH/2gAMAwEAAhADEAAAAVocEKpibf/EABoQAAMBAAMAAAAAAAAAAAAAAAABAhEDEjH/2gAIAQEAAQUC71iQ5YuKUYX7/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFhEAAwAAAAAAAAAAAAAAAAAAAAER/9oACAECAQE/AaiM/8QAGxAAAgEFAAAAAAAAAAAAAAAAAAEhEBExQZH/2gAIAQEABj8CLSyFxG6ZZ//EABwQAQABBAMAAAAAAAAAAAAAAAEAEUFRgSFxwf/aAAgBAQABPyE4AGphJqPbEKIjV3E1vmFPZP/aAAwDAQACAAMAAAAQUM//xAAXEQEBAQEAAAAAAAAAAAAAAAABABFh/9oACAEDAQE/ENSHl//EABgRAAIDAAAAAAAAAAAAAAAAAAABETFR/9oACAECAQE/EJKRgz//xAAaEAEBAQADAQAAAAAAAAAAAAABEQAhQWGB/9oACAEBAAE/EAcl5KEQfM08YysKVIAqn2d5YyorveQLHs0CFxn/2Q=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"uol output\"\n        title=\"uol output\"\n        src=\"/static/d068b09179d2fac329ed722c8820855c/1c72d/uol_output.jpg\"\n        srcset=\"/static/d068b09179d2fac329ed722c8820855c/a80bd/uol_output.jpg 148w,\n/static/d068b09179d2fac329ed722c8820855c/1c91a/uol_output.jpg 295w,\n/static/d068b09179d2fac329ed722c8820855c/1c72d/uol_output.jpg 590w,\n/static/d068b09179d2fac329ed722c8820855c/a8a14/uol_output.jpg 885w,\n/static/d068b09179d2fac329ed722c8820855c/fbd2c/uol_output.jpg 1180w,\n/static/d068b09179d2fac329ed722c8820855c/c58a3/uol_output.jpg 1500w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<h1>Images Representation</h1>\n<h2>Use Pre-trained CNN to generate activation maps</h2>\n<p>Deep convolutional neural network can output the activation map, which are features representing the content or style of an image. In this project, a ImageNet pretrained vgg16 network will be used to output the feature at different layers.</p>\n<p>VGG 16 is a deep CNN including 5 convolutional layers, 2 fully connetced layers and 1 softmax output layer. In this project, only the convolutional layers will be used as they will output the activation maps.</p>\n<p>The architecture of VGG16 is on the following:</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/db1c097ad63b388bcd303d0a65fee384/5a190/vgg16.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 23.64864864864865%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAIAAADKYVtkAAAACXBIWXMAAAsSAAALEgHS3X78AAAA30lEQVQY002P3XKEIAyFff/Hq107a51ZWX9GwICKCSoizXrVL3fJOTlJVjwefdcdIVybJ2tSjCEFIEgpyd65xVuLbiYf43KE8zy3mxgjCzLUcgW9HQebo/c0L3RudrfDyOVE3YGeG9EZXDsApTUROedCCIiYESLAaIxp3/XzJ2+FkFJ+5Tl3ePd1Xemmqn6NteM4CiGa5s2a16vOpplZ5CBb1ZV9tW/7uvr8uyLC9A9O01p/pMsyTRPne+8zO33sPMZ1Fa9aKcUvFUXBuwGAPQYAke/DsizVzSAleZJK/QE9JhkdfL3I6QAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"vgg16\"\n        title=\"vgg16\"\n        src=\"/static/db1c097ad63b388bcd303d0a65fee384/fcda8/vgg16.png\"\n        srcset=\"/static/db1c097ad63b388bcd303d0a65fee384/12f09/vgg16.png 148w,\n/static/db1c097ad63b388bcd303d0a65fee384/e4a3f/vgg16.png 295w,\n/static/db1c097ad63b388bcd303d0a65fee384/fcda8/vgg16.png 590w,\n/static/db1c097ad63b388bcd303d0a65fee384/5a190/vgg16.png 800w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>VGG16 takes 224 as the input size and all the convolutional layers are hidden layers.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/3d3d1764d8e9bbff8810f2631bc8ff58/2e237/layer2.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 48.64864864864865%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAIAAAA7N+mxAAAACXBIWXMAAAsSAAALEgHS3X78AAACUElEQVQozxVQy2oTUQAdXIgLEdwJbqQV0S5asNpYqyLWPq2ZZJpmZu7NvfN+z9zJTNo0TaJpQtMnNmltFC0tigqigkJdCG500YWLiqhFP8Gdn6DT3TkHDudBabqV5nhJUURFYXmgGibL86IkeYRgbuJy76XbmrxW4T8/x+tTlnGrz5DjxGSnRwf729ooP8xjUXI8YrueJCtBblKQZNt2ZqYLw+N07Ga8bThZFkd3CN2sks1m1TB5vad9xYSxjnMUwiJNJ3gIeAATyXFBFBPJJMcBWdUkdiIVax9IJdixwWXAwqFY2WHS3Ig9RteKVn9fFxWYDuKgZpq6YQKELZ8AhAxd10lua4r5pZ764A5P5eyHjZVyNgwstZK3FmuF1nKlr6ebcgwbpDnN0BVVYyE0XIeDUFUVzSKbFXnX7nhjXa2Wg3opX6revVMuF/LFuRxbI+z5riuUgA96AhEBlIkAxiiRZHiQgRnUevCo9fRl4/XOWc08frqjd3AE0gP00EC9aN9bLaRZQPnZEIui7Xuu62BR8H0/opbjOo679fzFu0/fP375cXRm7Vjn9WvdF0eGbvCp8blZs9lYKJZKFAfgWDwOEAQZQDNJJAgJhonEg+fzxfX1jdX7TbSUNsOTCnPGFGVCdEOOXkvZxKfq8wue5+pGNFnho822wx841Sh5Mj/DQUnV5G9vj/z7c3hj8cKTpdlnj+ddnGnVCgJgqf2f+3tf90jgGZaGBZFkA4SxYVrZIMyFAcQAInb3/Ym/vw9t1ztfba/Nh3GajjfqFQGk/wMC6fL+c4uafQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"layer2\"\n        title=\"layer2\"\n        src=\"/static/3d3d1764d8e9bbff8810f2631bc8ff58/fcda8/layer2.png\"\n        srcset=\"/static/3d3d1764d8e9bbff8810f2631bc8ff58/12f09/layer2.png 148w,\n/static/3d3d1764d8e9bbff8810f2631bc8ff58/e4a3f/layer2.png 295w,\n/static/3d3d1764d8e9bbff8810f2631bc8ff58/fcda8/layer2.png 590w,\n/static/3d3d1764d8e9bbff8810f2631bc8ff58/2e237/layer2.png 790w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>Layer 2 of the CNN. The left image represents what the CNN has learned and the right image has parts of actual images.</p>\n<ul>\n<li>In layer 2 of the CNN the model is already picking up more interesting shapes than just diagonal lines. In the sixth square (counting horizontally) you can see that the model is picking up circular shapes. Also, the last square is looking at corners.</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/f9dcb43e3297f438b3c71729c2a96d5a/5a190/layer3.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 37.16216216216216%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAIAAACHqfpvAAAACXBIWXMAAAsSAAALEgHS3X78AAABfUlEQVQY0y1QTU/CQBDtr/GkiR68ExMTvwniFwJFU0r9QEq7O7vdLbQo1gJWajUxkuDNaGICwsHEi2d/iPg/3Ca+vLyZw5t5k5EwtYjFEAAQgiEuGAgCjBljtbq6sZZMTGnbme/Pr37/HojGdaVQXABnB5/vSgYmYsw0kYmwEWtMwzQxoTbn6cRs6UgJ/Choep1aRTtUlYPDleXExubabehJlmUxxk0Mwi0ygVCIG6CMuTZ/zsz1bCMvZ7dSq3C05zfdtt/Q9KZStj+GbxIhVFBEIYRjiQH/ydTqz0+jopJMp0qZfEvf6fq3w9FYLajH8syYFyS9alQNM3YjQEKQIIgtYiNmVlle9FDJ58dXarp7lvQv+P2Fjs5ySEs/XRPpfTQeDIZuo0GAUmJR8T/KxOWc27W64znUqeTaKBspq69EDlz6EnZu7lpydsmjqvQ7mUx+fh57vXYQBDcCXUHRhWEYRVGzbsjZ/Ut+oqrbgefC7vqDfnLulh371G+wP2/Uw61+8hKpAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"layer3\"\n        title=\"layer3\"\n        src=\"/static/f9dcb43e3297f438b3c71729c2a96d5a/fcda8/layer3.png\"\n        srcset=\"/static/f9dcb43e3297f438b3c71729c2a96d5a/12f09/layer3.png 148w,\n/static/f9dcb43e3297f438b3c71729c2a96d5a/e4a3f/layer3.png 295w,\n/static/f9dcb43e3297f438b3c71729c2a96d5a/fcda8/layer3.png 590w,\n/static/f9dcb43e3297f438b3c71729c2a96d5a/5a190/layer3.png 800w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<ul>\n<li>In layer 3 we can see that the model is starting to learn more specific things. The first square shows that the model is now able to recognize geometrical patterns. The sixth square is recognizing car tires. And the eleventh square is recognizing people.</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/538599044d8f9033312285511b290641/00d43/layer5.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 24.324324324324326%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAIAAADKYVtkAAAACXBIWXMAAAsSAAALEgHS3X78AAABG0lEQVQY0w2NS0/CQBhF++uMG1YoaBqRCKJjpw9KCkO/zqOPEWpqSynRxKgLo4GdsjRqMETj33Ju7uom5x6NizCgjDIuotj3XWSgkecSxxGC52VFyBiA+hBQoFFe2qjhoQYy6tjorlePWhRLxSsyTqQ3wFxmljs8PWtNr2Re3UIAjHPKVMJZkUTkKHbbrqO36ruz+UJjQgSMKbmCab9l4Q67lGR0OE06WRqPfYBAhRKA+2J+zSOk14SnD3p7H39bTUrJ1DkLlToB07ebWQY5G+b2QZEKNatfUA1oUZYm7p3s18h503baX5+v2uZ7s6gWgoeTSVqlsWceJ6j7MLzIqPX+tt7+/C6XK8VzLqqbO4ytgY0z0G1n5+nl+R+wLZRKtKZErAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"layer5\"\n        title=\"layer5\"\n        src=\"/static/538599044d8f9033312285511b290641/fcda8/layer5.png\"\n        srcset=\"/static/538599044d8f9033312285511b290641/12f09/layer5.png 148w,\n/static/538599044d8f9033312285511b290641/e4a3f/layer5.png 295w,\n/static/538599044d8f9033312285511b290641/fcda8/layer5.png 590w,\n/static/538599044d8f9033312285511b290641/efc66/layer5.png 885w,\n/static/538599044d8f9033312285511b290641/00d43/layer5.png 1000w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<ul>\n<li>Finally, layers 4 and 5 continue this trend. Layer 5 is picking up tings that are very useful for our dogs and cats problem. It is also recognizing unicycles and bird/reptile eyes. Be aware that these images only show a very small fraction of things learned by each layer.</li>\n</ul>\n<p>As the network went deeper, the features became more high-level and abstrated for human to recongnize. The pretrained vgg16 will be able to filter out the objects in one image.</p>\n<h2>Representation of Content</h2>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/d20eef1a53fd3fa204018097dd48d381/bca35/rep_content.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 79.05405405405406%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAAAsSAAALEgHS3X78AAACHUlEQVQ4y3VU2XKjMBDk/79u35xKquIYG5tTB+hCQvSOYG2D41VBgaDV6pmeUYZ3Y6Zrnh/Ttmtxu91wvpxR1RVijCtsXoC7pdmO59/P9Ly/29GiLEscj0fk5xxDP+ww2zUPwleirTp+7tALCWMMBj3A1QbQhMH8ljTbqtsSOeugmIIXDlgjXEOla1ZxScu76LJXMiEETvkJjDFUZQUu+SZf62JrLbq2Q57naJoGIYSnwi2Z1gacC/ycfuCDB+Mczo2/IqibGh+fn2TShQhrTISd503Id2BxOeFa/EBISc4y3C5f9NP9CqvrOnwe/uB6LVBeT/Cmfrq8glbgqEtM4+pimCYIXqGXLbSxGMdxR5pI5riGanSPvpd093dCAowG3qlH8tu2BWeC0qBRVRWGYXgqjR5xWpWnjXo5oCC138fvNeSWQkhhlOUNEynzPqBuK1T8SibJxaj7SOXTdQ2pEVBKQzuNvDlCEo4LjiyBk5pkwDCox8IADz62u9KIUyS1Na7UNck8RnlWk4T07JnDFEraVVB5MFvvCNxkdnPpGI7NFyzlVEhBcw4f91Wwaz0dhgWQ6kopBSY7KhtHKfDrtyCprqflNnFAoFy+dlr22j7jZJfD4FJcIPt+ca4oCgjFEGYPG/SycYzT2/7PXpvbUHErcja5m5/POBwOi8tJlQ3moep/h8mvw0FSUScy6ywdVfVSDvfj6l3fb+s4jb/9vOBeeklLEAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"rep content\"\n        title=\"rep content\"\n        src=\"/static/d20eef1a53fd3fa204018097dd48d381/fcda8/rep_content.png\"\n        srcset=\"/static/d20eef1a53fd3fa204018097dd48d381/12f09/rep_content.png 148w,\n/static/d20eef1a53fd3fa204018097dd48d381/e4a3f/rep_content.png 295w,\n/static/d20eef1a53fd3fa204018097dd48d381/fcda8/rep_content.png 590w,\n/static/d20eef1a53fd3fa204018097dd48d381/bca35/rep_content.png 683w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>The structure of the content image could be easily extracted using the output of the last convolutional layer of vgg16.</p>\n<h2>Representation of Style</h2>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/986fc3f1ebbd6c5d5803aab6c1ab8807/62de4/rep_style.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 53.37837837837838%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsSAAALEgHS3X78AAABPUlEQVQoz21Si46DMAzj/79yd7pptwF98yoDHw4LqjgiRQXVcRyn1bquKIP/U56QQkLXdWjaBu/3G1exLAuGYUBKCdEH3L5uqHgxzzOmadozZxhr4K1Hignee2hTnnm7V1zf92jbFl3qNsKIV/1CRdA4jpLspgXOO1hrEWM8CKmUGMXnD6lzTvBMIaTCZV0OpXVdS6ELTr7LEYnZ8StCCKKQFjWmwf1+3wlZTL/YlZG6fVRjjBRpUCFxTPWV6oil11QrhLzU8yrKkflNpedlalS8VP9UIcHnZOSPJVTCsa+wQpjVl6Lz+dTXwEVQKbGXCukBN8ksPTuro2/0ijhiiC0nOgijixjjgId94GmeUlQSyqibKm6TBClF/Px+o25qGf8/4dYtbK/ceisPUxdTEo7TeLxJeSqmlf8rW/4AZjNc60hUJXsAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"rep style\"\n        title=\"rep style\"\n        src=\"/static/986fc3f1ebbd6c5d5803aab6c1ab8807/fcda8/rep_style.png\"\n        srcset=\"/static/986fc3f1ebbd6c5d5803aab6c1ab8807/12f09/rep_style.png 148w,\n/static/986fc3f1ebbd6c5d5803aab6c1ab8807/e4a3f/rep_style.png 295w,\n/static/986fc3f1ebbd6c5d5803aab6c1ab8807/fcda8/rep_style.png 590w,\n/static/986fc3f1ebbd6c5d5803aab6c1ab8807/62de4/rep_style.png 746w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>Similarly, the style of one image could also be extratced using the same method.</p>\n<h2>Feature and Gram Matrix</h2>\n<p>The activation map is a combined matrix which are high-level features human can easily recongnize.</p>\n<p>In style transfer, network need to convert them into another shape for the traning and testing procedure.</p>\n<ul>\n<li>First, convert the activation map into feature matirx.</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 475px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/3d1d42e258bf0bcd10b07e2b626101b9/466da/feature_matrix.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 55.4054054054054%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsSAAALEgHS3X78AAABmUlEQVQoz3VSDW/qMAzs//9zexowCWlUglJKurWFtE3zfcsFwd4kMDKXS+KL7brAE4sxZmzbFnVdo2kafO4+UZ/qp/f+x4J/z5xGsVNzwvF4xG63y+6cy+d3DCH8iSvwwu6iwzBkpABtf9hnEWbsvcfmY/MnrhjHEdM0gciMhBCPYGMM3v694Xw+o0pZ8my9WeNyueB99Z55VVXoug5936NJ9wouDmnzUB1Q7kuIbwGpJNSiUJYlrlJmATqzlYkzhkg+XIbMudZa/5YsF4nteYtts8XquEL9XaPvevj0s85CO43FLNjU64zkLFk7k/FRcmrlrWfJPQJssAjRQymVS2Iv2RK+LtkeO0NOY65AjhLWWozpnJwtKqKL8EMSkQ6hs/CNRmws1NcE8SXySxSz2mLRC0Kb8KrgnceiEvcBRpvHVy9iiDcxlfIbE0oLzAHqOkO0STAkOs9ZcEroxIJpGLMIM+e+mlV+lKW/HBtmw5JpnABjTUaXGjPOtxaQs2QKs0VcF6+Gmhc4LjQGc594HydyIs2mcjmbtB/HEVRC7KPVMAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"feature matrix\"\n        title=\"feature matrix\"\n        src=\"/static/3d1d42e258bf0bcd10b07e2b626101b9/466da/feature_matrix.png\"\n        srcset=\"/static/3d1d42e258bf0bcd10b07e2b626101b9/12f09/feature_matrix.png 148w,\n/static/3d1d42e258bf0bcd10b07e2b626101b9/e4a3f/feature_matrix.png 295w,\n/static/3d1d42e258bf0bcd10b07e2b626101b9/466da/feature_matrix.png 475w\"\n        sizes=\"(max-width: 475px) 100vw, 475px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>Each row of feature matrix represents different features, each column represent each pixel in activation map.</p>\n<p>The feature matrix contains all the inforamtion in style image.</p>\n<p>Another information needs to be known is the relationship between different features. The inner product of the feature matrix could describe the relationship in a clear manner. The new matrix is named as gram matrix.</p>\n<p>In python, the gram matrix could be easily calculated (F is feature matrix):</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">def Gram(F):\n    return np.dot(F.T, F) / F.size</code></pre></div>\n<ul>\n<li>The gram matrix is illustrated on the following. Each element in the gram matrix will represent 2 features on the row and column respectively.</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 424px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/e6590ccc3dbb0c50055b3e011f261194/1cfa9/gram_matrix.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsSAAALEgHS3X78AAACpklEQVQ4y41U227aQBD1P1fKP1SNlNeqfazylB9I1VZRpCgUE4IxwY6UQgoFJ1BuBhtf16c7Y9ZxTJA60mi9F585c2Z2NZQsyzJ29V3dq9pbaxreMHUwEQlSkSJJE56LtZxPQx6zWOyR2AMsbz6vntHoN1B7qOHh+YHX4skWyTRAMguRejEEMohUQIgX18qMyoB+6MMaW7iwL+AsnTyiL92T7krf4E3TykBV+lEaIU1TRHGE1WqFx199dLtddAwT5nULZkuOnQ5M00SHxo55WEPDMFD/Wcfl5SX71dUVblu3uLu7g2VZ6N5bsO9t2LbNQWidXKOf/cjHbDNDb9qDs3KQiQznX8+x3W5ZlziO8b/GDG2pld7TcaafYbQY8YbRNnh8f/wBxycnuQRRBF3X0TLyPdd1MVss4K7XeReoonihh8Hf3zCHJnqTHm82b5sIggA3zSbaUiMFuJAA8/mctaXvUK6RJ0mCOIkloKyByKgBcot3PddutzGdTotU6GeaUxDf95md4zjwPA9ryVB5XmWpmVjKvopSiDBlAKraeDzmQBSd9FSpqfTWpfkrDYWfIrY3fAPiSVAwnEwmnJ4lK6kK8/HzJ3w5PS00XMp2Wrnuaw0zyYqvUygQ9WXnSlqGaeDp6YlTGo1GrB+B1up1XNdqDEAMiT15wbB6wUWap9wyWhgOh8V6EIbMSBlJQM1OxQnlHmm7Dbb7N4Voc5VldRWg53tcFJKAGG82G8zmM85AsSNAcq16h9Mdw8bNDQaDAX9TW1DKBJTtziiA4Z8hvv34fvj5egFs8GECI9EJkNlJXyyXDEaa1hs63h0dFYT2AMsp9x/7xTrpRAxVRhRgKYGrb8BBQLr45u6GKI3KRSHtqKWqj7J26LVWVSxLUX4kaK4ClDvlHx+3AMLN9dZIAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"gram matrix\"\n        title=\"gram matrix\"\n        src=\"/static/e6590ccc3dbb0c50055b3e011f261194/1cfa9/gram_matrix.png\"\n        srcset=\"/static/e6590ccc3dbb0c50055b3e011f261194/12f09/gram_matrix.png 148w,\n/static/e6590ccc3dbb0c50055b3e011f261194/e4a3f/gram_matrix.png 295w,\n/static/e6590ccc3dbb0c50055b3e011f261194/1cfa9/gram_matrix.png 424w\"\n        sizes=\"(max-width: 424px) 100vw, 424px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>If one element on the gram matrix is large, the relation between these 2 features will be stronger. For example, in one cell, the row represent the tree, the column is flower, the value is larger means this artist prefers the combination of tree and flower.</p>\n<p>The size of gram matrix is only determined by the number of feature map. In style transfer, the input size is not strictly defined.</p>\n<h1>Training Progress</h1>\n<p>The whole process is showed on the following.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/da2ff99480227e9353883c1846687931/e4611/style_transfer_sketch.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 127.02702702702702%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAZCAIAAAC+dZmEAAAACXBIWXMAAC4jAAAuIwF4pT92AAADC0lEQVQ4y41UyY4cRRD1b/rMyfIX4BsnHzgZJIT4AXzAJ7gZDgiJA0gzlrE98jLYrumpPSv3LXIjsrrabTMecHRVKysyX74XEZlxo3zEMr7Rc8f/1tMpiMs0yTzZoqBAOsxXu1GusZxcsLNdzlLQJZYScuY+DyYRW3L+L3BOIYJMIJE/gYrAU7LbFPdpNNeCUzCgW6TFQV2dI6jOyyaB3gtOk8k6XAXXSTCTIU9BtSnaVQWAeAv8PMeNvPiYenOt7GCnnMN+HFNcxEiX11wtzm94jDybcAWMKo0JggatcsREFetNTy6GpR1pKzXbVgmfmf83GAF+nj0h+ETn0EP48Lp9sZvePL94zNSyxoa/jJFfAacUhHBdB5ynEFZmTfg4s54p6oM75nU8gPPBUqrHIChVRynmEIxVRIwduVBGFHSBz2udj2DvvbXWGKOkrHsARAA5I1+vhVBWUEkkxQgGfEIMRzBShBAQzxhTWlePc8gpKF3GkTOCsnuyW+i4DCOfRqT/AAwACEYSjaEirTHILIaBta0SjKIGPkhGFaWG86NslIqEyAzW8r4XTeMpjUpFa0XX0beNogQDbueG00mMk16WfV4q2DmntYYQrJSKMSsEMtecYfwYxbJQNi1iwiLPc6sZR3VHsF0tYnm954yhkK0SMYp5nrtWsIVrapySnJK2RedRNmKQHGXHlLQx+Pmu4Bi/4WKYL6mYOtIoyfDTCL7tPqwJw52c98hptQS3nV4vpV6InMZxagZ6KTRmvlNk1oRUZkiZ2A2Mfw5SM5tm0hZqJULMu57tOoxWrIXNMURM/zAusaQiAI/38Xje+/a7259/cf+HB8ZW5T/98vvNO1/euvvVbyen+wU/Pvz1szvffP39zxBd4ZAVbGDM9snJn2d//cFJv/c8e3Z2+uTR2fkrqbYUvnx1fvr46a4bkTj1+uP3+dChSlGhXNi87xH5vVaDnUTCB+C4Wj5A67XAGsxbx6meel9jHLEHuv/pnu/6El56TGxtncxj99lzfip4VZWx6VQJMb/ft/8BeH+i/pcXvO8AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"style transfer sketch\"\n        title=\"style transfer sketch\"\n        src=\"/static/da2ff99480227e9353883c1846687931/fcda8/style_transfer_sketch.png\"\n        srcset=\"/static/da2ff99480227e9353883c1846687931/12f09/style_transfer_sketch.png 148w,\n/static/da2ff99480227e9353883c1846687931/e4a3f/style_transfer_sketch.png 295w,\n/static/da2ff99480227e9353883c1846687931/fcda8/style_transfer_sketch.png 590w,\n/static/da2ff99480227e9353883c1846687931/efc66/style_transfer_sketch.png 885w,\n/static/da2ff99480227e9353883c1846687931/c83ae/style_transfer_sketch.png 1180w,\n/static/da2ff99480227e9353883c1846687931/e4611/style_transfer_sketch.png 1298w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<ul>\n<li>In the forward propagation, input the style image and content image into the network, extracted the feature.</li>\n<li>For each the content image, the content loss is determined as the the sum of all the training images.</li>\n<li>The cost function is the sum of the style loss and content loss.</li>\n<li>In the forward propagation, compute the gradient of total loss over the content image. Take the gradient descent until total loss converges.</li>\n<li>The content loss is a determined value defined by the training images.</li>\n</ul>\n<h2>Minimize the loss</h2>\n<p>The calculation equation of the style loss and content loss is actually the equation of mean square function (MSE).</p>\n<h2>MSE Equation</h2>\n<p>In the training the loss will be the Mean Square Error (MSE) equation. </p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/5832a13becfbaed8bbd194efe7dc89f4/9100a/mse.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 39.86486486486486%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAIABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAEF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB3oFB/8QAFhABAQEAAAAAAAAAAAAAAAAAAAEx/9oACAEBAAEFAmI//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFBABAAAAAAAAAAAAAAAAAAAAEP/aAAgBAQAGPwJ//8QAGhAAAQUBAAAAAAAAAAAAAAAAEQABITFxQf/aAAgBAQABPyEObjEXtLYi6v/aAAwDAQACAAMAAAAQgA//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAaEAEBAAIDAAAAAAAAAAAAAAABEQBBITFR/9oACAEBAAE/ECtS6GFVdPOmCFdrxqGf/9k='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"mse\"\n        title=\"mse\"\n        src=\"/static/5832a13becfbaed8bbd194efe7dc89f4/1c72d/mse.jpg\"\n        srcset=\"/static/5832a13becfbaed8bbd194efe7dc89f4/a80bd/mse.jpg 148w,\n/static/5832a13becfbaed8bbd194efe7dc89f4/1c91a/mse.jpg 295w,\n/static/5832a13becfbaed8bbd194efe7dc89f4/1c72d/mse.jpg 590w,\n/static/5832a13becfbaed8bbd194efe7dc89f4/a8a14/mse.jpg 885w,\n/static/5832a13becfbaed8bbd194efe7dc89f4/9100a/mse.jpg 959w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<h2>Definition of Total Loss</h2>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 476px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/cf32ed1f1c05cd420539d3c047fa6ba9/f2205/total.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 10.81081081081081%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAACCAYAAABYBvyLAAAACXBIWXMAAAsSAAALEgHS3X78AAAAYklEQVQI1z2NOQ5EMQxC//0PmSKrsq9KSkammMIyPCz89d4RY8QYA6LXWnjv/X2tFa01jrC9N+69yDkzK6WQiRb+yZFSisB7z/JzDlJKPNZaw1pLH0LgnnNSO+eYS4cxhk9/6ISWqYNg674AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"total\"\n        title=\"total\"\n        src=\"/static/cf32ed1f1c05cd420539d3c047fa6ba9/f2205/total.png\"\n        srcset=\"/static/cf32ed1f1c05cd420539d3c047fa6ba9/12f09/total.png 148w,\n/static/cf32ed1f1c05cd420539d3c047fa6ba9/e4a3f/total.png 295w,\n/static/cf32ed1f1c05cd420539d3c047fa6ba9/f2205/total.png 476w\"\n        sizes=\"(max-width: 476px) 100vw, 476px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<h2>Training Loss Plot</h2>\n<ul>\n<li>The loss plot in the training progress. It only takes 4 epoches, approximately 320000 iterations.</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/6605827edb897b19e1c54c041bcc7e9b/084e2/loss_plot.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 85.8108108108108%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAARCAYAAADdRIy+AAAACXBIWXMAAAsSAAALEgHS3X78AAAB+UlEQVQ4y51U/XOiMBDl//+z+uu1nZuCVr5FBAWkUSsQEsK7TarOaXXO3s4s5GPz8l42WUsphWEY0DQNri1JEriuizRNzd9xHLzZNjZVhXtmacCyLFFRUN/34JyfPY5jeJ6H5XKJMAxNezabYbVeY9t0+CQSXdei7Tq0bQspJSyNKkRP3xHjOEJvcPJ7tj8c4C+W8KMY0+nEKGgMeAdr1AzZForArk1vcOEUq6OafY0uf8YicPDy+puYu6jr2qgyDOsiwyDFbZAr1zaoAWKQ6IUwIFquZieob+kQtvChjGycF92ze/N6XOfAMCxiF8MDgKe5m6zpphjAXkhs0giy5w8xvLeJTqIBXGY5oql9wXD8D8AzQ93J45DuVHsp50HYbwx1Zx4FyFfFeeIn0m8y3LMa7x5l+ivE3MkTy4sEYPw3Qz0gqFEmPmw/AlenRRpEPeQ4vrAjoMLheH4sixEuMuwl0KsfJdtI5vwombdbiK7EcMiQ2E/IywWiLMJk+oogsOH5DsLoHX4wga/b4RTz+QzzmMb8NyouqQE1xUEjl0WOrtmS76A4w65KwIoIbRmAb2J8rj1k/guaKiSPcChDpLNfdEwO9isXDVuBbXdg7OPrDKUcLuh3XNJ7pWQ1HKuyxrr6QDhPUWwYCmr3FM4F1dG/cqTftK44fwDLtyp0nSn7qQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"loss plot\"\n        title=\"loss plot\"\n        src=\"/static/6605827edb897b19e1c54c041bcc7e9b/fcda8/loss_plot.png\"\n        srcset=\"/static/6605827edb897b19e1c54c041bcc7e9b/12f09/loss_plot.png 148w,\n/static/6605827edb897b19e1c54c041bcc7e9b/e4a3f/loss_plot.png 295w,\n/static/6605827edb897b19e1c54c041bcc7e9b/fcda8/loss_plot.png 590w,\n/static/6605827edb897b19e1c54c041bcc7e9b/084e2/loss_plot.png 632w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<h1>Conclusion</h1>\n<ul>\n<li>VGG 16 was used to extract the feature and reconstruct images.</li>\n<li>Training the network takes very long time, a light CNN may be used for time reduction.</li>\n<li>The tune of parameter Î± and Î² to change the output.</li>\n</ul>\n<h1>Demo Video</h1>\n<p>The real-time demo video is here:</p>\n<p><a href=\"https://www.youtube.com/watch?v=5WqvDl81Cj0s\">https://www.youtube.com/watch?v=5WqvDl81Cj0s</a></p>\n<p>Or referenced the gif:</p>\n<p><img src=\"/6517f354dface24f613f24431dc169f8/demo.gif\"></p>\n<h1>Training Dataset</h1>\n<p>The training dataset uses the Microsoft COCO 2014 dataset.</p>\n<p>The size of the dataset is 14GB which has 80000 images in total.</p>\n<h1>GitHub Page</h1>\n<p><a href=\"https://github.com/jmnie/CS539-ML-18F-Project\">https://github.com/jmnie/CS539-ML-18F-Project</a></p>\n<h1>Presentation Slides</h1>\n<p><a href=\"https://prezi.com/kxdwilsggigw/machine_learning_pre/?utm_campaign=share&#x26;utm_medium=copy\">https://prezi.com/kxdwilsggigw/machine_learning_pre/?utm_campaign=share&#x26;utm_medium=copy</a></p>","frontmatter":{"title":"WPI CS 539 Project - Images Style Transfer Using CNN","date":"December 09, 2018","description":"This webpage is the host page for the WPI CS 539 Group project 2018 Fall."}}},"pageContext":{"slug":"/ml_project/","previous":{"fields":{"slug":"/hello-world/"},"frontmatter":{"title":"Hello World"}},"next":{"fields":{"slug":"/study_data_structure/"},"frontmatter":{"title":"Learning Data Structure & Algorithm"}}}}