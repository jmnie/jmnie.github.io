<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>blog</title>
  
  
  <link href="https://jmnie.github.io/atom.xml" rel="self"/>
  
  <link href="https://jmnie.github.io/"/>
  <updated>2022-12-25T10:15:32.041Z</updated>
  <id>https://jmnie.github.io/</id>
  
  <author>
    <name>Jiaming Nie</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>和2022作别</title>
    <link href="https://jmnie.github.io/2022/12/25/2022-farewell-mess/"/>
    <id>https://jmnie.github.io/2022/12/25/2022-farewell-mess/</id>
    <published>2022-12-25T00:00:00.000Z</published>
    <updated>2022-12-25T10:15:32.041Z</updated>
    
    <content type="html"><![CDATA[<p>2022年结束了。想起来去年写下2021年总结时，还是满怀壮志的。2021年是一个转变的时候，总算是从一个心态很飘的时候进行了一定的转变，保持了一定的运动量，也换了工作。当时对2022年还是充满期待的。但现在回看过去，对这些成就都算不上的变化，心态上太过飘飘然，实际上很多目标都没做到。</p><p>2022年这一整年过的都很混乱。生日这天更是感染了新冠，虽然问题不严重，但是很干扰自己的心智。今天终于有空静下心来写写2022了。</p><h2 id="1月-5月"><a href="#1月-5月" class="headerlink" title="1月-5月"></a>1月-5月</h2><p>前三个月我已经没什么印象了，当时在公司还在用Python写一些IoT的项目（实际就是糊一些Python脚本而已）。过年结束返回公司的时候去客户那里拜访过，也算是个有趣的经历。</p><p>3月上旬时上海已经封控了很多地方，对这些新闻不在意的我，觉得没什么大不了的，继续上班就是，应该没事的。有些敏感度高的人已经察觉了不同，在这时就已经开始离开上海去其他地方了。到了3月22日，早晨我正准备去上班，突然间小区出不去了。再出小区的时候已经是5月31日了。</p><p>这段时间实际上我是几乎没有好好写代码的，每天仿佛有强迫症一样，焦虑到极点。我无法控制自己的情绪。除了封城70天给人带来的精神创伤，我也开始意识到另外一件事情：和父母尽可能保持远离。也许从2020年回国时，在美国找不到工作，悻悻而归的时候，除了自身的无能，还有就是精神上对父母的依赖。我必须学会精神独立，切开与他们之间的联系，真正长大。</p><h2 id="6月-12月"><a href="#6月-12月" class="headerlink" title="6月-12月"></a>6月-12月</h2><p>6月-8月这三个月整个人处于一种创伤后的恢复。仿佛对一切都不在意，一切都无所谓。赚钱？工作？名利？一切的一切？Fuck them。整个人的情绪处于飘扬的状态。</p><p>8月-12月整个人情绪稳定了一些，但还是时不时会爆发一下，暴怒或者大喊。</p><h2 id><a href="#" class="headerlink" title></a></h2><p>今年是被外界因素彻底打乱没有什么收获的一年。最近在做自动化测试开发，内心不太情愿。想起过去几年，似乎没有怎么选对路，或者方法错误。</p><p>2017年时，转去CS是个正确的决定，但不应该在2018年一整年把时间都耗在机器学习上。2018年下半年应该去做fullstack的项目，而不是直到整个2019年都无事可做。现在回头看，2019年真的是太重要而被浪费的一年，这一年也彻底决定了我注定和美国无缘，拿不到互联网的大包裹，最后只能饮恨回国。</p><p>2020年回国去轻松的外企也没错，不应该把大把时间浪费，而是应该注重提高自己，不要浪费时间。2021年还好，成功换了工作，但是收入依然很低。比不过去做量化的，去大厂的，起步慢了，整体也慢了。</p><p>当我在2022年听到他人当国际高中课程教师年入60万，比我大几岁早点做对选择去咨询，去创业，收入上百万时，看着自己手上那点可怜的税后收入，再看看自己的年龄，再看看自己从本科到研究生多花的这些钱，无一不在预示着自己的失败。</p><p>2023年我没有什么新的目标和计划，只有一件事情，希望自己能多赚点钱，经济实力能够强大一点。不要再浑浑噩噩下去了。</p>]]></content>
    
    
    <summary type="html">This post is about some details and mistakes I had ran into.</summary>
    
    
    
    
    <category term="non-tech" scheme="https://jmnie.github.io/tags/non-tech/"/>
    
    <category term="CN" scheme="https://jmnie.github.io/tags/CN/"/>
    
  </entry>
  
  <entry>
    <title>Parallel Computing Notes</title>
    <link href="https://jmnie.github.io/2022/04/20/parallel_computing/"/>
    <id>https://jmnie.github.io/2022/04/20/parallel_computing/</id>
    <published>2022-04-20T00:00:00.000Z</published>
    <updated>2022-09-01T14:10:59.896Z</updated>
    
    <content type="html"><![CDATA[<p>This blog is about some basic concepts of parallel computing. It includes the concept and comparison between serial computing and parallel computing. </p><h1 id="Serial-Computing"><a href="#Serial-Computing" class="headerlink" title="Serial Computing"></a>Serial Computing</h1><p><img src="/2022/04/20/parallel_computing/images/serial_computing.png" alt="Serial Computing"></p><ul><li>A problem is broken into a discrete series of instructions</li><li>Instructions are executed sequentially one after another</li><li>Only one instruction may execute at any moment of time</li></ul><h1 id="Parallel-Computing"><a href="#Parallel-Computing" class="headerlink" title="Parallel Computing"></a>Parallel Computing</h1><p><img src="/2022/04/20/parallel_computing/images/parallel_computing.png" alt="Parallel Computing"></p><ul><li>Be divided into sub-problem which can be solved simultaneously</li><li>Execute multiple program instructions at any moment in time</li><li>High e ciency with multiple computation resources than single computation resource</li></ul><h1 id="Parallelism-vs-Concurrency"><a href="#Parallelism-vs-Concurrency" class="headerlink" title="Parallelism vs. Concurrency"></a>Parallelism vs. Concurrency</h1><h2 id="Concurrency"><a href="#Concurrency" class="headerlink" title="Concurrency"></a>Concurrency</h2><p><img src="/2022/04/20/parallel_computing/images/concurrency.png" alt="Concurrency"></p><ul><li>Concurrency, application making progress on more than one task.</li><li>Concurrency means executing multiple tasks at the same time but not necessarily simultaneously.</li></ul><h2 id="Parallelism"><a href="#Parallelism" class="headerlink" title="Parallelism"></a>Parallelism</h2><p><img src="/2022/04/20/parallel_computing/images/parallelism.png" alt="Parallelism"></p><ul><li>Parallelism means that an application splits its tasks up into smaller subtasks which can be processed in parallel, for instance on multiple CPUs at the exact same time (simultaneously).</li></ul><h2 id="Matrix-Multiplication-Using-Parallel-Methods"><a href="#Matrix-Multiplication-Using-Parallel-Methods" class="headerlink" title="Matrix Multiplication Using Parallel Methods"></a>Matrix Multiplication Using Parallel Methods</h2><h3 id="Matrix-Computation"><a href="#Matrix-Computation" class="headerlink" title="Matrix Computation"></a>Matrix Computation</h3><p><img src="/2022/04/20/parallel_computing/images/matrix_computation.jpeg" alt="Matrix Computation"></p><p>Sequential Algorithm</p><ul><li>Using nested loops in Code, time Complexity <em>O(N3)</em></li></ul><h3 id="Parallel-Methods"><a href="#Parallel-Methods" class="headerlink" title="Parallel Methods"></a>Parallel Methods</h3><p>Parallel Algorithm</p><p><img src="/2022/04/20/parallel_computing/images/matrix_compute_parallel.png" alt="Parallel Methods"></p><ul><li>Divided Matrix A and B into small blocks</li><li>Using parallel loops in Code, time Complexity O(M*N2)</li></ul><h2 id="Neural-Network-Initialize-Compute-and-Update-Parameters"><a href="#Neural-Network-Initialize-Compute-and-Update-Parameters" class="headerlink" title="Neural Network: Initialize, Compute and Update Parameters"></a>Neural Network: Initialize, Compute and Update Parameters</h2><p><img src="/2022/04/20/parallel_computing/images/neural_network.png" alt="Neural Network"></p><ul><li>Output &#x3D; Input * HiddenParameters</li><li>Number of parameters is pretty huge</li></ul><h2 id="Map-Reduce-Large-Scale-Matrix-Multiplication"><a href="#Map-Reduce-Large-Scale-Matrix-Multiplication" class="headerlink" title="Map-Reduce: Large-Scale Matrix Multiplication"></a>Map-Reduce: Large-Scale Matrix Multiplication</h2><p><img src="/2022/04/20/parallel_computing/images/map_reduce.png" alt="Map Reduce"></p><ul><li>Parallel and distributed algorithm processing big data sets.</li><li>Proposed by Google, implemented in Hadoop and Spark.</li></ul><h1 id="Application-Scenraio"><a href="#Application-Scenraio" class="headerlink" title="Application Scenraio"></a>Application Scenraio</h1><p><img src="/2022/04/20/parallel_computing/images/app.png" alt="Applications"></p><p>Scenarios that require processing large amounts of data in sophisticated<br>way.</p><ul><li>“Big Data”, databases and data mining</li><li>Artificial Intelligence</li><li>Pharmaceutical design</li><li>Financial and economic modeling</li></ul><h2 id="GPU-and-Parallel-Computing"><a href="#GPU-and-Parallel-Computing" class="headerlink" title="GPU and Parallel Computing"></a>GPU and Parallel Computing</h2><p><img src="/2022/04/20/parallel_computing/images/gpu.png" alt="GPU Framework"></p><ul><li>GPUs are designed to handle parallel processing more e ciently.</li></ul><h2 id="CUDA-Compute-Uni-ed-Device-Architecture"><a href="#CUDA-Compute-Uni-ed-Device-Architecture" class="headerlink" title="CUDA - Compute Uni ed Device Architecture"></a>CUDA - Compute Uni ed Device Architecture</h2><ul><li>A parallel computing platform and programming model that enables dramatic increases in computing performance by harnessing the power of the graphics processing unit (GPU).</li><li>Developed and released by NVIDIA in 2006</li><li>Can run on all of NVIDIA’s latest discrete GPUs</li><li>Extension of the C, C++, and Fortran languages</li><li>Operating Systems that Support it: Windows XP and later, Linux, and Mac OS X</li></ul>]]></content>
    
    
    <summary type="html">This blog is a transcript about basic intro to Parallel Computing</summary>
    
    
    
    
    <category term="tech" scheme="https://jmnie.github.io/tags/tech/"/>
    
    <category term="EN" scheme="https://jmnie.github.io/tags/EN/"/>
    
  </entry>
  
  <entry>
    <title>WeChat MiniProgram Development</title>
    <link href="https://jmnie.github.io/2022/01/15/wechat_miniprogram/"/>
    <id>https://jmnie.github.io/2022/01/15/wechat_miniprogram/</id>
    <published>2022-01-15T00:00:00.000Z</published>
    <updated>2022-09-01T14:10:59.909Z</updated>
    
    <content type="html"><![CDATA[<p>This blog is about WeChat Mini-Program development. This blog will not dive very deep about the usage of API and related development toolchains. It will focus on high-level stuff. Some parts of the content were presented in work. </p><h1 id="WeChat-Mini-Program-Status-Quo"><a href="#WeChat-Mini-Program-Status-Quo" class="headerlink" title="WeChat Mini-Program Status Quo"></a>WeChat Mini-Program Status Quo</h1><ul><li>Over 400 million Daily active users</li><li>Over 3.5 million Mini-Programs</li><li>Over 60% of WeChat users use Mini-Programs</li></ul><p><img src="/2022/01/15/wechat_miniprogram/images/miniprogram.png" alt="MiniProgram"></p><h1 id="Development-View-of-WeChat-Mini-Program"><a href="#Development-View-of-WeChat-Mini-Program" class="headerlink" title="Development View of WeChat Mini-Program"></a>Development View of WeChat Mini-Program</h1><p>This part is about the development view of the Mini-Program. It’s generally about the structure, project kernal and project structure. </p><h2 id="WeChat-Mini-Program-Runtime"><a href="#WeChat-Mini-Program-Runtime" class="headerlink" title="WeChat Mini-Program Runtime"></a>WeChat Mini-Program Runtime</h2><ul><li>Rendering Layer: WXML &amp; WXSS (HTML &amp; CSS)</li><li>JavaScript is the Development Language</li></ul><p><img src="/2022/01/15/wechat_miniprogram/images/runtime.png" alt="MiniProgram Runtime"></p><h2 id="WeChat-Mini-Program-Project-Kernel"><a href="#WeChat-Mini-Program-Project-Kernel" class="headerlink" title="WeChat Mini-Program Project Kernel"></a>WeChat Mini-Program Project Kernel</h2><ul><li><p>iOS, iPad OS &amp; Mac OS: JavaScriptCore &amp; WKWeb View</p></li><li><p>Android: V8 &amp; XWeb</p></li><li><p>Windows (Win WeChat): Chrome core</p></li><li><p>IDE on Windows: NW.js &amp; Chromium Webview</p></li></ul><h3 id="Sample-Screenshot-of-IDE"><a href="#Sample-Screenshot-of-IDE" class="headerlink" title="Sample Screenshot of IDE"></a>Sample Screenshot of IDE</h3><p><img src="/2022/01/15/wechat_miniprogram/images/ide.png" alt="IDE"></p><h2 id="WeChat-Mini-Program-Project-Structure"><a href="#WeChat-Mini-Program-Project-Structure" class="headerlink" title="WeChat Mini-Program Project Structure"></a>WeChat Mini-Program Project Structure</h2><p><img src="/2022/01/15/wechat_miniprogram/images/project_structure.png" alt="Project Structure"></p><ul><li><p>In App.js,  global data object will be stored here. </p></li><li><p>In Pages, the first page will be indexed as the Main page.</p></li></ul><h1 id="Portfolio"><a href="#Portfolio" class="headerlink" title="Portfolio"></a>Portfolio</h1><p>In 2021, I colloborated with <a href="https://www.instagram.com/inuhikru/">Hikaru</a> and we successfully launched two mini-programs. Thank you Hikaru, hope we can continue cooperating in the future!</p><h2 id="Matrix-Scan"><a href="#Matrix-Scan" class="headerlink" title="Matrix Scan"></a>Matrix Scan</h2><p>Matrix scan is a mini-program launched for a small exhibition. Participants can use this miniprogram to unlock different icons designed for the exhibition. (Designer: <a href="https://www.instagram.com/inuhikru/">Hikaru</a>)</p><p><img src="/2022/01/15/wechat_miniprogram/images/matrix_scan.png" alt="matrix_scan"></p><p><img src="/2022/01/15/wechat_miniprogram/images/live_usage.png" alt="Live on Exhibition"></p><h2 id="PelletCat"><a href="#PelletCat" class="headerlink" title="PelletCat"></a>PelletCat</h2><p>PelltCat is a miniprogram of a small game for identification testing. You can search “PelletCat” in WeChat and launch the app, play with it.</p><p><img src="/2022/01/15/wechat_miniprogram/images/pellet_cat.png" alt="PelletCat"></p><h1 id="Load-Testing-on-WeChat-Mini-Program"><a href="#Load-Testing-on-WeChat-Mini-Program" class="headerlink" title="Load Testing on WeChat Mini-Program"></a>Load Testing on WeChat Mini-Program</h1><ul><li><p>Using JMeter</p></li><li><p>WeTest - An Official WeChat Testing Framework</p></li></ul><h1 id="Slides-Link"><a href="#Slides-Link" class="headerlink" title="Slides Link"></a>Slides Link</h1><p>Here is the slide version of this blog: <a href="https://prezi.com/view/AVc0ZGhMkUtyBuBelO7z/">Slides</a></p>]]></content>
    
    
    <summary type="html">This blog is a transcript about basic intro to WeChat Mini-Program.</summary>
    
    
    
    
    <category term="tech" scheme="https://jmnie.github.io/tags/tech/"/>
    
    <category term="EN" scheme="https://jmnie.github.io/tags/EN/"/>
    
  </entry>
  
  <entry>
    <title>2022, Far and Beyond</title>
    <link href="https://jmnie.github.io/2021/12/20/2021-summary/"/>
    <id>https://jmnie.github.io/2021/12/20/2021-summary/</id>
    <published>2021-12-19T16:50:00.000Z</published>
    <updated>2022-09-01T14:10:59.835Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1"><a href="#1" class="headerlink" title="1."></a>1.</h3><p>2020年12月的某个阴天，我在龙阳路地铁站等待下一班进城的地铁。周围很开阔，阴冷的风吹来，让我想起，2019年12月21号，在纽约的地铁上，从法拉盛到曼哈顿。从玻璃窗外看到的城市，也是这么开阔。</p><p>只是上海的地铁上没有乞讨的卖艺人。</p><h3 id="2"><a href="#2" class="headerlink" title="2."></a>2.</h3><p>去年结束时，我给自己定了一个目标，“能够随时随地做任何事情”。Anytime, Anywhere, Anything. 以前的我总是在某个特定的环境下才能做某件事情。在这个过程浪费了大量的时间和精力。与环境过于绑定并不是一件好事，这种低效无用的“仪式感”也在损耗效率。</p><p>这一年快结束时再看，执行起来的效果并没有那么好。我想看的书没有看完，想要坚持刷的题没刷完，想要学习的某样东西没有学完…但是跟一年前和两年前的自己比起来，还是做了一些事情。2021年跑了1200km，在前司时坚持一周游3km，通过跳槽强迫自己重新刷了leetcode前350道题，时隔两年后重新开始做饭，以及认识了很棒的朋友，一起做了有趣的东西，传递了快乐。（虽然和自己的计划对比，并没有完成1500km的目标，也没有把体重降到预期的水平，还是没有拿到想要的offer，只看了几本书，更多的还在列表里，到现在连一页都没翻。就在今天还被提醒前新工作的两个月工作没到预期。）</p><p>但是至少，在过去的一年里，有了一点这种感觉：自己好像是一匹马在拉着雪橇前进，留下了一点车辙印；而不是在更早的两年里，感受不到一切，被命运的马拖拽着前进。</p><h3 id="3"><a href="#3" class="headerlink" title="3."></a>3.</h3><p>大概是5月的一天，和一个朋友出来玩，他说，“现在大部分人活得太过单一了。好像除了一些基本的追求，其他方向上毫无建树。我想要拥有多一点不同的爱好和技能。”</p><p>5年前还在上本科时，我曾有过类似表述，就是某校某专业的大部分学生活得实在是太一样了。无论是在国内，还是去了英国，所有人都在拼了命刷分，为了顺利入学IC，所有人都在选FYP给分最轻松的老师。什么只能去UCL了？算了一下不用那么紧张了，因为一等已经稳了。</p><p>但是当我真的离开这种环境时，发现自己只不过从一个漩涡离开到了另一个漩涡而已。在美国时，所有人都想转CS，每个人都在刷题，讨论的话题离不开有没有找到实习有没有拿到亚麻谷歌Meta的offer，几年以后又在焦虑自己的级别package有没有买房。回国不回国，其实没什么两样。即使自己有多么不喜欢大多数人的生活，但是实际上自己并不能真的置身事外。现实的压力永远摆在哪里。上海是国内最多元化的城市之一，在这里可以遇到很多活得很不一样的人，但是很难说每个人都可以远离现实的压力。</p><p>即使如此，多重认同和多重身份依然是我的追求。虽然很多时候只是给自己贴上很廉价的标签，但是我依然乐在其中。人生永远缺乏探索和体验。就像这位朋友，也从来没有停止追求不同的可能性。</p><h3 id="4"><a href="#4" class="headerlink" title="4."></a>4.</h3><p>在2020年，我变成了宿命论者。在此之前，无论是经历什么不同的事情，一直都有种”I can do all things.”的信念。就算结果没有达到预期，但是我相信我永远能顺利度过。但是经历了无法改变的客观变化后，仿佛发生的一切都变成了已经命中注定的事情。面临相同的困境，以前认识的人能够坚持度过，而我最终没能坚持到底。我一度认为这是我的精神属性不够强，随后把这件事情归因为宿命。</p><p>在今年看过加缪以后，我又有些改观。实际上大多数时候都无法逃离西西弗斯式的重复劳作。即使不断切换环境，新鲜感很快就会消失。仿佛永远都无法跳出漩涡，永远都在重复。</p><p>我不想假定西西弗斯一直开心。也许这就是大多数人的宿命，在没有尽头的时间线上不停重复。虽然不能改变最终宏大的结果，但是可以在无限重复的时间线上去做一些微小的改变 — （虽然，无论是多重身份也好，还是多重认同，抑或是任何没有任何意义的标签，都是如此，是大海上一朵转瞬即逝的浪花。）</p><p>无数微小的瞬间填满了人的一生。也许正是这些无尽的轮回中的微小的瞬间，才是人生真正有意义的地方。</p><h3 id="5"><a href="#5" class="headerlink" title="5."></a>5.</h3><p>12月20号这天一过，就又老了一岁。</p><p>年龄焦虑和身材焦虑是最近一年多两个永恒的话题。今年我在一个场合表达过，自己心态似乎永远停留在24岁左右，恍惚过来，原来已经过去三年了。</p><p>我后来反复在想为什么会是24岁，其实答案也很简单，那就是24岁之后的那两年里，应该在这个年纪做的事情，一件都没有按部就班完成。所以自己会沉浸于焦虑之中，变得患得患失。</p><p>但是这一年里终于把24岁应该做到的事情终于费劲完成了一遍。但其实并没有想象中那么开心。甚至在8月19号这天陷入了极度emo，因为早就该做到的事情，我足足晚了两年多才经历到。就像是跑一场漫长的超级马拉松，我不知道在哪一段被命运击昏，终于跨过这个补给点时，心情变得无比复杂。</p><p>但是时间仍在继续向前，还有无数微小的瞬间等待我去填满。西西弗斯并不会停止他的劳作。</p><blockquote><p>“不要在乎面子，不要在乎结果，做了才有结果，不要逃避，要勇敢。<br>当你好好做完一件事的时候，那天的食物会变得更加好吃。<br>就算是为了美味的食物和畅快的心情，扔掉一些本来会很介意的东西吧。”</p></blockquote><blockquote><p>“<em>That’s all I do all day. I’d just be the catcher in the rye and all. I know it’s crazy, but that’s the only thing I’d really like to be.</em>“</p></blockquote><pre><code>----- J. D. Salinger, The Cather in the Rye</code></pre><p>Back and Forth, Everyday. </p>]]></content>
    
    
    <summary type="html">The Summary for 2021</summary>
    
    
    
    
    <category term="non-tech" scheme="https://jmnie.github.io/tags/non-tech/"/>
    
    <category term="CN" scheme="https://jmnie.github.io/tags/CN/"/>
    
  </entry>
  
  <entry>
    <title>A Brief Intro to WebRTC</title>
    <link href="https://jmnie.github.io/2021/04/15/notes-for-WebRTC/"/>
    <id>https://jmnie.github.io/2021/04/15/notes-for-WebRTC/</id>
    <published>2021-04-15T00:00:00.000Z</published>
    <updated>2022-09-01T14:10:59.877Z</updated>
    
    <content type="html"><![CDATA[<p>This blog is about the notes of the WebRTC of an internal knowledge sharing. This blog will only discuss about high-level architecture and API in WebRTC.</p><h1 id="WebRTC-in-A-Nutshell"><a href="#WebRTC-in-A-Nutshell" class="headerlink" title="WebRTC in A Nutshell"></a>WebRTC in A Nutshell</h1><h2 id="WebRTC-Web-Real-time-Communication"><a href="#WebRTC-Web-Real-time-Communication" class="headerlink" title="WebRTC: Web Real-time Communication"></a>WebRTC: Web Real-time Communication</h2><blockquote><p>“<em>WebRTC is a new front in the long war for an open and unencumbered web.</em>“</p></blockquote><pre><code>----- Brendan Eich, Mozilla CTO and inventor of JavaScript</code></pre><h2 id="Brief-Functionalities"><a href="#Brief-Functionalities" class="headerlink" title="Brief Functionalities"></a>Brief Functionalities</h2><ul><li>Open Source Project, providing browsers, mobile applications with simple API.</li><li>Supports direct peer-to-peer audio and video communication inside web pages.</li><li>Standards published by W3C and IETF (Internet Engineering Task Force).</li><li>Developed in C++ and JavaScript.</li></ul><h2 id="WebRTC-Architecture-Framework"><a href="#WebRTC-Architecture-Framework" class="headerlink" title="WebRTC Architecture (Framework)"></a>WebRTC Architecture (Framework)</h2><p><img src="/2021/04/15/notes-for-WebRTC/images/webrtcArchitecture.png" alt="WebRTC Architecture"></p><h2 id="WebRTC-Applications-Acorss-Platforms"><a href="#WebRTC-Applications-Acorss-Platforms" class="headerlink" title="WebRTC Applications Acorss Platforms"></a>WebRTC Applications Acorss Platforms</h2><ul><li>Chrome</li><li>Chrome on Android</li><li>FireFox</li><li>Opera</li><li>And ** IE ** doesn’t support WebRTC.</li></ul><p><img src="/2021/04/15/notes-for-WebRTC/images/firefoxChrome.jpg" alt="Application on Browsers"><br><img src="/2021/04/15/notes-for-WebRTC/images/android.jpg" alt="Application on Mobile Applications"></p><h2 id="Main-Tasks-of-WebRTC"><a href="#Main-Tasks-of-WebRTC" class="headerlink" title="Main Tasks of WebRTC"></a>Main Tasks of WebRTC</h2><ul><li>Acquiring audio and video</li><li>Communicating audio and video</li><li>Communicating arbitrary data</li></ul><h1 id="WebRTC-JavaScript-API"><a href="#WebRTC-JavaScript-API" class="headerlink" title="WebRTC JavaScript API"></a>WebRTC JavaScript API</h1><p>In this section, three main JavaScript API will be discuessed here, which are:</p><ul><li>MediaStream (getUserMedia)</li><li>RTCConnection</li><li>RTCDataChannel</li></ul><h2 id="MediaStream-getUserMedia"><a href="#MediaStream-getUserMedia" class="headerlink" title="MediaStream (getUserMedia)"></a>MediaStream (getUserMedia)</h2><ul><li>Represent a stream of audio and&#x2F;or video</li><li>Can contain multiple ‘tracks’</li><li>Obtain MediaStream with navigator.getUserMedia()</li></ul><p><img src="/2021/04/15/notes-for-WebRTC/images/mediaStream.png" alt="Application on Browsers"> </p><h3 id="JavaScript-API-Sample"><a href="#JavaScript-API-Sample" class="headerlink" title="JavaScript API Sample"></a>JavaScript API Sample</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">var constraints = &#123;video: true&#125;;</span><br><span class="line"></span><br><span class="line">function successCallback(stream) &#123;</span><br><span class="line">  var video = document.querySelector(&quot;video&quot;);</span><br><span class="line">  video.src = window.URL.createObjectURL(stream);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">function errorCallback(error) &#123;</span><br><span class="line">  console.log(&quot;navigator.getUserMedia error: &quot;, error);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">navigator.getUserMedia(constraints, successCallback, errorCallback);</span><br></pre></td></tr></table></figure><p>A simple demo here: <a href="https://andrei.codes/ascii-camera/">https://andrei.codes/ascii-camera/</a></p><h2 id="RTCPeerConnection-Audio-and-Video-Communication-between-Peers"><a href="#RTCPeerConnection-Audio-and-Video-Communication-between-Peers" class="headerlink" title="RTCPeerConnection: Audio and Video Communication between Peers"></a>RTCPeerConnection: Audio and Video Communication between Peers</h2><p><img src="/2021/04/15/notes-for-WebRTC/images/mediaStream.png" alt="Communicate Media Streams"></p><h3 id="RTCPeerConnection-Does-A-Lot"><a href="#RTCPeerConnection-Does-A-Lot" class="headerlink" title="RTCPeerConnection Does A Lot"></a>RTCPeerConnection Does A Lot</h3><ul><li>Signal Processing</li><li>Codec Handling</li><li>Peer to Peer Communication</li><li>Security</li><li>Bandwidth Management</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">pc = new RTCPeerConnection(null);</span><br><span class="line">pc.onaddstream = gotRemoteStream;</span><br><span class="line">pc.addStream(localStream);</span><br><span class="line">pc.createOffer(gotOffer);</span><br><span class="line"></span><br><span class="line">function gotOffer(desc) &#123;</span><br><span class="line">  pc.setLocalDescription(desc);</span><br><span class="line">  sendOffer(desc);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">function gotAnswer(desc) &#123;</span><br><span class="line">  pc.setRemoteDescription(desc);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">function gotRemoteStream(e) &#123;</span><br><span class="line">  attachMediaStream(remoteVideo, e.stream);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>A simple demo: <a href="https://simpl.info/rtcpeerconnection/">https://simpl.info/rtcpeerconnection/</a></p><h2 id="RTCDataChannel-Birdirectional-Communication-of-Arbitrary-Data-Between-Peers"><a href="#RTCDataChannel-Birdirectional-Communication-of-Arbitrary-Data-Between-Peers" class="headerlink" title="RTCDataChannel: Birdirectional Communication of Arbitrary Data Between Peers"></a>RTCDataChannel: Birdirectional Communication of Arbitrary Data Between Peers</h2><p><img src="/2021/04/15/notes-for-WebRTC/images/rtc_connect.png" alt="RTCDataChannel Application"></p><h3 id="RTCDataChannel"><a href="#RTCDataChannel" class="headerlink" title="RTCDataChannel"></a>RTCDataChannel</h3><ul><li>Sample API as WebSockets</li><li>Ultra-low Latency</li><li>Unreliable or Reliable</li><li>Secure</li></ul><p>Sample code of the API:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">var pc = new webkitRTCPeerConnection(servers,</span><br><span class="line">  &#123;optional: [&#123;RtpDataChannels: true&#125;]&#125;);</span><br><span class="line"></span><br><span class="line">pc.ondatachannel = function(event) &#123;</span><br><span class="line">  receiveChannel = event.channel;</span><br><span class="line">  receiveChannel.onmessage = function(event)&#123;</span><br><span class="line">    document.querySelector(&quot;div#receive&quot;).innerHTML = event.data;</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">sendChannel = pc.createDataChannel(&quot;sendDataChannel&quot;, &#123;reliable: false&#125;);</span><br><span class="line"></span><br><span class="line">document.querySelector(&quot;button#send&quot;).onclick = function ()&#123;</span><br><span class="line">  var data = document.querySelector(&quot;textarea#send&quot;).value;</span><br><span class="line">  sendChannel.send(data);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>A simple demo: <a href="http://www.simpl.info/dc">http://www.simpl.info/dc</a></p><h2 id="Servers-and-Protocols"><a href="#Servers-and-Protocols" class="headerlink" title="Servers and Protocols"></a>Servers and Protocols</h2><p>WebRTC based on peer-to-peer communication, but servers are needed.</p><h3 id="Abstract-Signaling"><a href="#Abstract-Signaling" class="headerlink" title="Abstract Signaling"></a>Abstract Signaling</h3><ul><li><p>Need to exchange “session description” objects</p><ul><li>What formats I support, what I want to send</li><li>Network Information for peer-to-peer setup</li></ul></li><li><p>Can use any messaging mechanism</p></li><li><p>Can use any messaging protocol</p></li></ul><h3 id="Signaling-Diagram"><a href="#Signaling-Diagram" class="headerlink" title="Signaling Diagram"></a>Signaling Diagram</h3><p><img src="/2021/04/15/notes-for-WebRTC/images/jsep.png" alt="Signaling Diagram"></p><h2 id="Several-Architectures"><a href="#Several-Architectures" class="headerlink" title="Several Architectures"></a>Several Architectures</h2><h3 id="Peer-to-Peer-one-to-one-call"><a href="#Peer-to-Peer-one-to-one-call" class="headerlink" title="Peer-to-Peer: one-to-one call"></a>Peer-to-Peer: one-to-one call</h3><p><img src="/2021/04/15/notes-for-WebRTC/images/p2p.png" alt="Peer-to-Peer"></p><h3 id="Mesh-small-N-way-Call"><a href="#Mesh-small-N-way-Call" class="headerlink" title="Mesh: small N-way Call"></a>Mesh: small N-way Call</h3><p><img src="/2021/04/15/notes-for-WebRTC/images/mesh.png" alt="Mesh: Small N-way Call">)</p><h3 id="Star-Medium-N-way-Call"><a href="#Star-Medium-N-way-Call" class="headerlink" title="Star: Medium N-way Call"></a>Star: Medium N-way Call</h3><p><img src="/2021/04/15/notes-for-WebRTC/images/star.png" alt="Star: Medium N-way Call">)</p><h3 id="MCU-Large-N-way-Call"><a href="#MCU-Large-N-way-Call" class="headerlink" title="MCU: Large N-way Call"></a>MCU: Large N-way Call</h3><p><img src="/2021/04/15/notes-for-WebRTC/images/mcu.png" alt="Star: Medium N-way Call">)</p><h1 id="Application-Scenarios"><a href="#Application-Scenarios" class="headerlink" title="Application Scenarios"></a>Application Scenarios</h1><p>There are mainly two application scenarios: small (or tiny) video&#x2F;audio meeting or some online learning session.</p><h2 id="Scenraio-I-Video-Conference"><a href="#Scenraio-I-Video-Conference" class="headerlink" title="Scenraio I: Video Conference"></a>Scenraio I: Video Conference</h2><p><img src="/2021/04/15/notes-for-WebRTC/images/s1_1.png" alt="Scenario I: P2P Communication">)</p><p><img src="/2021/04/15/notes-for-WebRTC/images/s1_2.png" alt="Scenario I: Signaling Mechanism">)</p><h2 id="Scenario-II-Live-Stream"><a href="#Scenario-II-Live-Stream" class="headerlink" title="Scenario II: Live Stream"></a>Scenario II: Live Stream</h2><p><img src="/2021/04/15/notes-for-WebRTC/images/s2.png" alt="Scenario II: Live Stream">)</p>]]></content>
    
    
    <summary type="html">This blog is a transcript about high-level intro to WebRTC.</summary>
    
    
    
    
    <category term="tech" scheme="https://jmnie.github.io/tags/tech/"/>
    
    <category term="EN" scheme="https://jmnie.github.io/tags/EN/"/>
    
  </entry>
  
  <entry>
    <title>Build Chromium and FireFox from Source Code (Windows as Example)</title>
    <link href="https://jmnie.github.io/2021/03/17/build_chromium_firefox/index/"/>
    <id>https://jmnie.github.io/2021/03/17/build_chromium_firefox/index/</id>
    <published>2021-03-17T00:00:00.000Z</published>
    <updated>2022-09-01T14:10:59.835Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Preface"><a href="#Preface" class="headerlink" title="Preface"></a>Preface</h2><p>Build project from source code is always an interesting stuff. This blog is about how to build chromium and firefox from source code.</p><p>Note: Actuallt it’s not a blog, it’s a small guidance for how to get through the whole workflow (Especially in some regions requiring proxy or VPN to access the chromium source code repository.)</p><h2 id="Build-chromium-from-source-code"><a href="#Build-chromium-from-source-code" class="headerlink" title="Build chromium from source code"></a>Build chromium from source code</h2><h2 id="Reference-Links"><a href="#Reference-Links" class="headerlink" title="Reference Links"></a>Reference Links</h2><p>The guidance is edited from an internal wiki page. Tried several times, very useful. Before the main content, here are some useful official links for Chromium project:</p><p>Here is the official link for building chromium on different platforms:<br><a href="https://www.chromium.org/developers/how-tos/get-the-code">The Chromium Projects</a></p><p>Official Guidance for building Chromium for Windows (A little verbose and more universal):<br><a href="https://chromium.googlesource.com/chromium/src/+/master/docs/windows_build_instructions.md">Build Chromium on Windows</a></p><p><a href="https://bitbucket.org/chromiumembedded/cef/src/master/">Chromium Embedded Framework, CEF</a> is a project for maintaining different branches of chromium source code and related work of chromium itself. </p><p>Here are 3 links that’s useful in building chromium from the CEF project:</p><p>It’s a wrap-up link for setting up on different OS.<br><a href="https://bitbucket.org/chromiumembedded/cef/wiki/MasterBuildQuickStart.md">Build QuickStart</a></p><p>A description which involves more details in environment variables and related configuration (on Windows).<br><a href="https://bitbucket.org/chromiumembedded/cef/wiki/AutomatedBuildSetup.md#markdown-header-windows-configuration">Build Setup</a></p><h2 id="Guidance"><a href="#Guidance" class="headerlink" title="Guidance"></a>Guidance</h2><h3 id="Pre-requisites"><a href="#Pre-requisites" class="headerlink" title="Pre-requisites"></a>Pre-requisites</h3><table><thead><tr><th>Actions</th><th>Remark</th><th>Reference</th></tr></thead><tbody><tr><td><strong>Install Visual Studio</strong></td><td>Community Edition has met the reuqirement. Note for the installation:</td><td><a href="https://chromium.googlesource.com/chromium/src/+/master/docs/windows_build_instructions.md">Chromium Offical Docs</a></td></tr><tr><td></td><td>1. Desktop development with C++ (including <strong>MFC and   ATL support</strong>)</td><td></td></tr><tr><td></td><td>2. Install Windows 10 SDK installed, latest version is preferred</td><td></td></tr><tr><td><strong>Setup depot_tools</strong></td><td><a href="http://commondatastorage.googleapis.com/chrome-infra-docs/flat/depot_tools/docs/html/depot_tools.html">depot_tools</a> is a tool for maintaing the source (Cubersome to use)</td><td><a href="http://commondatastorage.googleapis.com/chrome-infra-docs/flat/depot_tools/docs/html/depot_tools_tutorial.html#_setting_up">depot_tools Doc</a></td></tr><tr><td>Add depot_tools to path (system environment variable on Win)</td><td>Unzip the folder, or you can git clone the <a href="https://chromium.googlesource.com/chromium/tools/depot_tools.git">repository</a></td><td>Add it to the system variables in case</td></tr><tr><td>Add system environment variable <strong>DEPOT_TOOLS_WIN_TOOLCHAIN: 0</strong></td><td>SET DEPOT_TOOLS_WIN_TOOLCHAIN&#x3D;0</td><td><a href="https://chromium.googlesource.com/chromium/src/+/master/docs/windows_build_instructions.md">Chromium Guide</a></td></tr><tr><td>Add system environment variables <strong>GYP_GENERATORS</strong> &amp; <strong>GYP_MSVS_VERSION</strong></td><td>SET GYP_GENERATORS&#x3D;msvs-ninja,ninja</td><td></td></tr><tr><td></td><td>SET GYP_MSVS_VERSION&#x3D;2019 (if you use other versions please chnage)</td><td></td></tr></tbody></table><p>These are environment settings for preparations of building chromium on Windows. </p><h3 id="Build-Chromium"><a href="#Build-Chromium" class="headerlink" title="Build Chromium"></a>Build Chromium</h3><p>After installing the Visual Studio and setting the environment variables, next step is to fetch the source code from Chromium source code repository. The following table is a detailed instruction (Note: ** Follow the step exactly one by one, especially setting the proxy **)</p><table><thead><tr><th>Phase</th><th>Run Command &amp; Operations</th><th>Running Path</th><th>Remark</th></tr></thead><tbody><tr><td><strong>Prepare</strong></td><td>netsh winhttp set proxy <a href="url:port">url:port</a></td><td></td><td><strong>Run the command in CMD</strong> in case did not work</td></tr><tr><td></td><td>git config –global user.name <your name></your></td><td></td><td>Set your git use info</td></tr><tr><td></td><td>git config –global user.email <your email></your></td><td></td><td>Set your git use info</td></tr><tr><td></td><td>git config –global http.proxy <a href="url:port">url:port</a></td><td></td><td>Set git proxy</td></tr><tr><td></td><td>git config –global https.proxy <a href="url:port">url:port</a></td><td></td><td>Note: when set https proxy, use <strong>http:&#x2F;&#x2F;</strong> ,do not use https:&#x2F;&#x2F;</td></tr><tr><td></td><td>set HTTP_PROXY&#x3D;<a href="url:port">url:port</a></td><td></td><td>Set global proxy</td></tr><tr><td></td><td>set HTTPS_PROXY&#x3D;<a href="url:port">url:port</a></td><td></td><td>when set https proxy, use <strong>http:&#x2F;&#x2F;</strong> ,do not use https:&#x2F;&#x2F;</td></tr><tr><td></td><td>set SOCKS5_PROXY&#x3D;<a href="url:port">url:port</a></td><td></td><td><strong>Compulsory.If SOCKS5 is not set, will encounter problems when running scripts in depot_tools</strong></td></tr><tr><td><strong>BOTO config</strong></td><td>This step is also to create the proxy.</td><td></td><td></td></tr><tr><td></td><td>Create a file with extension “.boto”, e.g. proxy_config.boto</td><td></td><td></td></tr><tr><td></td><td>The BOTO content:</td><td></td><td></td></tr><tr><td></td><td>[Boto]</td><td></td><td>Save the file somewhere you like, for example, C:\proxy_config.boto</td></tr><tr><td></td><td>proxy&#x3D;<proxy_url></proxy_url></td><td></td><td></td></tr><tr><td></td><td>proxy_port&#x3D;<proxy_port></proxy_port></td><td></td><td></td></tr><tr><td></td><td><strong>SET NO_AUTH_BOTO_CONFIG&#x3D;C:\proxy_config.boto</strong></td><td></td><td>In Windows, add a new variable in system environment variables.</td></tr><tr><td><strong>Running gclient</strong></td><td>gclient</td><td></td><td><strong>Run the command in CMD</strong>, it will install an individual python and other tools.</td></tr><tr><td><strong>Fetch Master</strong></td><td>fetch chromium</td><td>Parent directory of chromium src directory</td><td>Download the source code from master, may take a very long time, depending on the internet connection.</td></tr><tr><td><strong>Update Master</strong></td><td>git checkout master</td><td>chromium src directory</td><td></td></tr><tr><td></td><td>git pull</td><td>chromium src directory</td><td>pull changes list</td></tr><tr><td></td><td>gclient sync</td><td>chromium src directory</td><td>synchronize dependencies and third parties</td></tr><tr><td><strong>Switch to working branch</strong></td><td>git checkout -b <local branch name> <tag name></tag></local></td><td>chromium src directory</td><td>example: git checkout -b Chromium_39.0.2171.71 39.0.2171.71. Go to <a href="http://www.chromium.org/developers/calendar">Chrome Calendar</a> to find latest stable branch (tag), in “Current Release Information”, win, stable, current_version</td></tr><tr><td></td><td></td><td></td><td>Note: you may need to run <strong>“git fetch –tags”</strong> to fetch all tags first</td></tr><tr><td></td><td>gclient sync –with_branch_heads –jobs 16</td><td>chromium src directory</td><td>to sync all solution related code, dependencies and third parties of current branch</td></tr><tr><td><strong>Generate solution file</strong></td><td>gn args out&#x2F;<build name></build></td><td>chromium src directory</td><td>for example: gn args out&#x2F;Default</td></tr><tr><td></td><td></td><td></td><td>in the opened editor, set at least following build args.</td></tr><tr><td></td><td></td><td></td><td><strong>is_debug&#x3D;false</strong></td></tr><tr><td></td><td></td><td></td><td><strong>target_cpu&#x3D;”x64”</strong></td></tr><tr><td></td><td></td><td></td><td>See <a href="https://chromium.googlesource.com/chromium/src/+/master/tools/gn/docs/quick_start.md">parameters</a></td></tr><tr><td><strong>Build solution</strong></td><td>ninja -C out&lt;build name&gt; chrome</td><td>chromium src directory</td><td>build x64 bit to src\out&lt;build name&gt; folder, could take 4 hours</td></tr><tr><td></td><td></td><td>See <a href="https://chromium.googlesource.com/chromium/src/+/master/docs/windows_build_instructions.md">build instructions</a></td><td></td></tr><tr><td></td><td></td><td>Note: you may need to add “C:\Program Files (x86)\Windows Kits\10\Include\10.0.16299.0\um” to PATH system environment variable</td><td></td></tr><tr><td></td><td></td><td>Note: you may need to modify <strong>“out\Default\environment.x64”</strong> file, changing all 10.0.15063.0 to 10.0.16299.0 (for correct Win SDK version).</td><td></td></tr></tbody></table><h2 id="Build-FireFox-from-source-code"><a href="#Build-FireFox-from-source-code" class="headerlink" title="Build FireFox from source code"></a>Build FireFox from source code</h2><p>Build from FireFox from source code is pretty easier. </p><h3 id="Reference-Links-1"><a href="#Reference-Links-1" class="headerlink" title="Reference Links"></a>Reference Links</h3><p>Here is the link for buidling Firefox on Windows (won’t paste the content here, just follow the instructions):</p><p><a href="https://firefox-source-docs.mozilla.org/setup/windows_build.html">Build FireFox on Windows</a></p><p>Remarks on the note:</p><ol><li>Install Python 3.x and Python 2.7 (not sure why the script still requires Python2 dependency, and set the environment variables on Windows if multiple versions of Python did not work as expected )</li><li>When set the system proxy, remember to set the following:<ul><li>http proxy</li><li>https proxy (when set https proxy, use <a href="http://your_proxy/">http://your_proxy</a> removing ‘s’)</li><li>socks5 proxy (crucial)</li></ul></li><li>If the toolchain ‘mach’ failed on certain steps, just perform some other actions.</li></ol><h3 id="Building-Old-Versions-FireFox"><a href="#Building-Old-Versions-FireFox" class="headerlink" title="Building Old Versions FireFox"></a>Building Old Versions FireFox</h3><p>(This section is added on 2021&#x2F;04&#x2F;08 ) When build FireFox with some lower versions, there are several problems I have seen:</p><ol><li>The Rust version is not compatiable</li><li>The script (Mainly in Python, for the purpose to update) needs to sync with the server and check the versions.</li></ol>]]></content>
    
    
    <summary type="html">This blog is a note recording the problems met when building chromium and firefox from source code.</summary>
    
    
    
    
    <category term="tech" scheme="https://jmnie.github.io/tags/tech/"/>
    
    <category term="EN" scheme="https://jmnie.github.io/tags/EN/"/>
    
  </entry>
  
  <entry>
    <title>Learning Data Structure &amp; Algorithm</title>
    <link href="https://jmnie.github.io/2020/09/03/study_data_structure/index/"/>
    <id>https://jmnie.github.io/2020/09/03/study_data_structure/index/</id>
    <published>2020-09-03T00:00:00.000Z</published>
    <updated>2022-09-01T14:10:59.909Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Preface"><a href="#Preface" class="headerlink" title="Preface"></a>Preface</h2><p>数据结构和算法属于基础的东西，有句话就是program &#x3D; data structure + algorithm. 数据结构构造不同的存储数据方式（往往根据现实需求），通过特定算法组成程序的逻辑，解决真实问题。实际中并不会去手写一个stack&#x2F;queue&#x2F;linkedlist来去解决问题，这些在不同语言中已经实现了，关键是用他们去解决一些问题（比如地图染色，找最大最小，etc）。</p><h2 id="书籍-Books"><a href="#书籍-Books" class="headerlink" title="书籍 Books"></a>书籍 Books</h2><h3 id="《算法导论》Introduction-to-Algorithms"><a href="#《算法导论》Introduction-to-Algorithms" class="headerlink" title="《算法导论》Introduction to Algorithms"></a>《算法导论》Introduction to Algorithms</h3><p>这本书从recursion开始讲起，包括不同的数据结构（stack|queue|heap|hash table|binary search tree),排序算法（merge sort|binary search|quick sort), 还有一部分图算法。</p><p>优点是：内容设置很合理，从最简单的递归－&gt;深度优先，广度优先，最简单的选择排序－&gt;二分查找－&gt;合并排序，快速排序，然后再次基础上讲图算法。<br>缺点是：每一章节会在数学论证上挖的比较深（比如各种算法的lower upper bound的证明，这种东西不太适合一般程序员，会让初学者顾此失彼。）</p><p>算法导论课后习题答案: <a href="https://sites.math.rutgers.edu/~ajl213/CLRS/CLRS.html">solution1</a>, <a href="https://walkccc.github.io/CLRS/">solution2</a>.</p><h3 id="《Algorithms》算法"><a href="#《Algorithms》算法" class="headerlink" title="《Algorithms》算法"></a>《Algorithms》算法</h3><p><a href="https://algs4.cs.princeton.edu/home/">地址</a> 这本书是普林斯顿一个教授写的，完全不用买纸质书，因为全书都已经在上述的地址里了，而且包括所有内容的相关代码。并且这门课在coursera上是有视频的，并且免费。</p><p>优点：极其注重实践，和算法导论完全不是一个风格，用的语言是Java（Java各种数据结构的API设计的很规范，有些动态语言如python很灵活，比如list本身就可以当作queue和stack用，对一些不是很熟悉的学习者来说，比如我，555，在练习的时候就会产生迷惑，对学习基础的内容反而不是很有帮助）。</p><p>缺点：对初学者极其不友好。这本书最好的用户是有了一定基础的学习者。coursera上的网课第一次作业就是union find, 而且几个视频的内容是算法导论一章才能讲完的。</p><h2 id="网课"><a href="#网课" class="headerlink" title="网课"></a>网课</h2><p>a. 算法导论是没有网课的，算法这本书有网课，但是并不适合初学者。</p><p>b. 九章算法只看过一些，好像价格也比较合理，时间比较灵活，并且比较实用，适合面试的人使用。</p><p>c. 一个英文的课程：<a href="https://www.educative.io/courses/grokking-the-coding-interview?aff=K7qB">course</a>. 这个我其实没上过，按月收费的，而且面向找工作的人，也不是很适合初学者。</p><p>d. 我之前旁听过来offer的直播课（每周固定时间），讲得不错，但是一是很贵，二是面向的人群是在美国找工作的人。</p><h2 id="leetcode-x2F-lintcode"><a href="#leetcode-x2F-lintcode" class="headerlink" title="leetcode&#x2F;lintcode"></a>leetcode&#x2F;lintcode</h2><p>我只用过leetcode，lintcode没用过，不过应该也类似。leetcode现在有1000多题，题目质量有好有坏，怎么做leetcode，不同的人也有不同的做法：</p><p>a. 爆刷流，按照题号直接一题一题做；</p><p>b. 精刷流，对于一道题可能会钻研半天，尝试使用不同的解法（bfs｜dfs）而且不达成100%（运行时间少于100%的人）不罢休。</p><p>不同的方法没有好坏之分，只有适合不适合。之前认识的朋友，有做了300-400就去了大厂的，也有leetcode全刷了一遍去大厂的，也有极其聪明200多去谷歌的。当然，大部分人属于第一种，对于大部分题目有个基础的认识，对于不同的数据结构有清晰的用法和场景，其实就足够了。</p><p>leetcode有个板块，<a href="https://leetcode.com/explore/learn/">explore&#x2F;learn</a>, 按照最基础的array&#x2F;linkedlist&#x2F;binary tree&#x2F;binary search tree&#x2F;hash table 来区分的。加在一起200题左右。并且每个部分先会有讲解，然后由浅入深的练习。（但是每个板块的最后几题有可能会出现hard）刚开始做的时候实在做不出来不一定非要钻牛角尖。这部分可以结合算法导论的理论部分，学习理论并且在这个板块中进行练习，个人觉得效果还行&#x3D; &#x3D;。<br>对于大部分面试来说 easy|medium （20% esay 80% medium） 绝对够用了，hard可以给学有余力或者大神去解决，而且个别hard题目解法比较刁钻。</p><p>在做完learn之后，可以参加leetcode的weekly contest，1小时30分钟 4道题目，有排名。刚开始学习的时候不建议参加&#x3D; &#x3D;因为很可能第一道题就不会做导致打击学习热情。</p><h2 id="为什么要刷题｜学习算法数据结构？"><a href="#为什么要刷题｜学习算法数据结构？" class="headerlink" title="为什么要刷题｜学习算法数据结构？"></a>为什么要刷题｜学习算法数据结构？</h2><p>a. 理论一点来说，算法和数据结构是学习cs的基础，坚实基础，永远都没有错。</p><p>b. 对于国外的公司（国内就是相当一部分外企+某些企业，如字节），刷题是成本最低的筛选方式。如果一个面试者题目都做得出来，那么要么很聪明，要么花了一部分时间，那么这样的人招进来，肯定符合要求。而且很多公司的项目组或者系统很复杂，进去一段时间内都在熟悉业务和整体架构，那么招个聪明或者辛勤努力的学习者，一定没错。</p><p>当然这种方式下存在两种人不适合这个筛选方式：（1）只会刷题工程能力很弱的 （2）工程能力很强但是不会刷题的。对于（1）给够一定时间学习就行了，只要脑子不笨或者愿意花时间，业务上的东西都会搞明白的，工程能力是可以慢慢培养的。对于（2），这种人有，但很少，比如2015年homebrew的作者去面试谷歌，因为不会翻转二叉树而挂掉面试（invert binary searh tree）。但是这样的人很少。没有哪一种方式是完美的～</p><p>c. 这个是玄学的说法，但是make sense: 刷题刷多了，经常动脑去思考，对于思考业务逻辑（还有工程能力）也是有一定帮助的～</p><h2 id="网盘？"><a href="#网盘？" class="headerlink" title="网盘？"></a>网盘？</h2><p>九章算法：<a href="https://pan.baidu.com/s/1_LRWPfuWd-Jp5yt1Ria07g">链接</a>  提取码: ybsn</p><p>我上过的来offer的讲义（这个讲义对很多题目的方法都很不错）：<br><a href="https://pan.baidu.com/s/1mqgQdtZ_PcGKiYmUZbSZsQ">链接</a>  提取码: h5zs</p>]]></content>
    
    
    <summary type="html">学习数据结构和算法的总结。</summary>
    
    
    
    
    <category term="CN" scheme="https://jmnie.github.io/tags/CN/"/>
    
    <category term="tech" scheme="https://jmnie.github.io/tags/tech/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://jmnie.github.io/2020/09/01/hello-world/index/"/>
    <id>https://jmnie.github.io/2020/09/01/hello-world/index/</id>
    <published>2020-09-01T00:00:00.000Z</published>
    <updated>2022-09-01T14:10:59.836Z</updated>
    
    <content type="html"><![CDATA[<p>This is actually my first Blog here. This site will be a place for backing up new ideas and any related progress from the work or just a note for something funny. </p><p>I’m Jiaming Nie, A software engineer who is weak in coding and interested in dreaming new ideas. </p><p>Some links about me:<br><a href="https://github.com/jmnie">GitHub Page</a>.</p><blockquote><p>Oh God, I could be bounded in a nutshell and count myself a king of infinite space,<br>were it not that I have bad dreams.<br>Small? No, I could live in a walnut shell and feel like the king of the universe.</p></blockquote><pre><code>------- Hamlet, Act 2 Sene 2, William Shakespeare</code></pre><blockquote><p>Do not quench your inspiration and your imagination;<br>do not become the slave of your model.</p></blockquote><pre><code>------- Vincent Van Gogh</code></pre>]]></content>
    
    
    <summary type="html">Hello World &amp; Writing Blog Here</summary>
    
    
    
    
    <category term="non-tech" scheme="https://jmnie.github.io/tags/non-tech/"/>
    
    <category term="EN" scheme="https://jmnie.github.io/tags/EN/"/>
    
  </entry>
  
  <entry>
    <title>WPI CS 539 Project - Images Style Transfer Using CNN</title>
    <link href="https://jmnie.github.io/2018/12/09/ml-project/"/>
    <id>https://jmnie.github.io/2018/12/09/ml-project/</id>
    <published>2018-12-09T10:00:00.000Z</published>
    <updated>2022-09-01T14:10:59.836Z</updated>
    
    <content type="html"><![CDATA[<p>This is the webpage of WPI CS 539 (Machine Learning) final project.</p><p>Group Member:</p><p>Jiaming Nie, Ruojun Li, Yu Li, Yang Tao, Guangda Li</p><h1 id="Introduction-To-Style-Transfer"><a href="#Introduction-To-Style-Transfer" class="headerlink" title="Introduction To Style Transfer"></a>Introduction To Style Transfer</h1><p>Style transfer is the technique of recomposing images in the style of other images. Three images will be taken, a content image, a style image and output image.</p><p>Deep convolutional neural network is a powerful tool to extract the feature which represents the styles. The style could be the structure of one painting, the way artists draw their paintings and the colors that the artists use. Representation of content images can also be extracted using the deep convolutional neural network.</p><p>A style transfer demo is illustrated on the following image:</p><p><img src="/2018/12/09/ml-project/images/uol_output.jpg"></p><h1 id="Images-Representation"><a href="#Images-Representation" class="headerlink" title="Images Representation"></a>Images Representation</h1><h2 id="Use-Pre-trained-CNN-to-generate-activation-maps"><a href="#Use-Pre-trained-CNN-to-generate-activation-maps" class="headerlink" title="Use Pre-trained CNN to generate activation maps"></a>Use Pre-trained CNN to generate activation maps</h2><p>Deep convolutional neural network can output the activation map, which are features representing the content or style of an image. In this project, a ImageNet pretrained vgg16 network will be used to output the feature at different layers.</p><p>VGG 16 is a deep CNN including 5 convolutional layers, 2 fully connetced layers and 1 softmax output layer. In this project, only the convolutional layers will be used as they will output the activation maps.</p><p>The architecture of VGG16 is on the following:</p><p><img src="/2018/12/09/ml-project/images/vgg16.png"></p><p>VGG16 takes 224 as the input size and all the convolutional layers are hidden layers.</p><p><img src="/2018/12/09/ml-project/images/layer2.png"></p><p>Layer 2 of the CNN. The left image represents what the CNN has learned and the right image has parts of actual images.</p><ul><li>In layer 2 of the CNN the model is already picking up more interesting shapes than just diagonal lines. In the sixth square (counting horizontally) you can see that the model is picking up circular shapes. Also, the last square is looking at corners.</li></ul><p><img src="/2018/12/09/ml-project/images/layer3.png"></p><ul><li>In layer 3 we can see that the model is starting to learn more specific things. The first square shows that the model is now able to recognize geometrical patterns. The sixth square is recognizing car tires. And the eleventh square is recognizing people.</li></ul><p><img src="/2018/12/09/ml-project/images/layer5.png"></p><ul><li>Finally, layers 4 and 5 continue this trend. Layer 5 is picking up tings that are very useful for our dogs and cats problem. It is also recognizing unicycles and bird&#x2F;reptile eyes. Be aware that these images only show a very small fraction of things learned by each layer.</li></ul><p>As the network went deeper, the features became more high-level and abstrated for human to recongnize. The pretrained vgg16 will be able to filter out the objects in one image.</p><h2 id="Representation-of-Content"><a href="#Representation-of-Content" class="headerlink" title="Representation of Content"></a>Representation of Content</h2><p><img src="/2018/12/09/ml-project/images/rep_content.png"></p><p>The structure of the content image could be easily extracted using the output of the last convolutional layer of vgg16.</p><h2 id="Representation-of-Style"><a href="#Representation-of-Style" class="headerlink" title="Representation of Style"></a>Representation of Style</h2><p><img src="/2018/12/09/ml-project/images/rep_style.png"></p><p>Similarly, the style of one image could also be extratced using the same method.</p><h2 id="Feature-and-Gram-Matrix"><a href="#Feature-and-Gram-Matrix" class="headerlink" title="Feature and Gram Matrix"></a>Feature and Gram Matrix</h2><p>The activation map is a combined matrix which are high-level features human can easily recongnize.</p><p>In style transfer, network need to convert them into another shape for the traning and testing procedure.</p><ul><li>First, convert the activation map into feature matirx.</li></ul><p><img src="/2018/12/09/ml-project/images/feature_matrix.png"></p><p>Each row of feature matrix represents different features, each column represent each pixel in activation map.</p><p>The feature matrix contains all the inforamtion in style image.</p><p>Another information needs to be known is the relationship between different features. The inner product of the feature matrix could describe the relationship in a clear manner. The new matrix is named as gram matrix.</p><p>In python, the gram matrix could be easily calculated (F is feature matrix):</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def Gram(F):</span><br><span class="line">    return np.dot(F.T, F) / F.size</span><br></pre></td></tr></table></figure><ul><li>The gram matrix is illustrated on the following. Each element in the gram matrix will represent 2 features on the row and column respectively.</li></ul><p><img src="/2018/12/09/ml-project/images/gram_matrix.png"></p><p>If one element on the gram matrix is large, the relation between these 2 features will be stronger. For example, in one cell, the row represent the tree, the column is flower, the value is larger means this artist prefers the combination of tree and flower.</p><p>The size of gram matrix is only determined by the number of feature map. In style transfer, the input size is not strictly defined.</p><h1 id="Training-Progress"><a href="#Training-Progress" class="headerlink" title="Training Progress"></a>Training Progress</h1><p>The whole process is showed on the following.</p><p><img src="/2018/12/09/ml-project/images/style_transfer_sketch.png"></p><ul><li><p>In the forward propagation, input the style image and content image into the network, extracted the feature.</p></li><li><p>For each the content image, the content loss is determined as the the sum of all the training images.</p></li><li><p>The cost function is the sum of the style loss and content loss.</p></li><li><p>In the forward propagation, compute the gradient of total loss over the content image. Take the gradient descent until total loss converges.</p></li><li><p>The content loss is a determined value defined by the training images.</p></li></ul><h2 id="Minimize-the-loss"><a href="#Minimize-the-loss" class="headerlink" title="Minimize the loss"></a>Minimize the loss</h2><p>The calculation equation of the style loss and content loss is actually the equation of mean square function (MSE).</p><h2 id="MSE-Equation"><a href="#MSE-Equation" class="headerlink" title="MSE Equation"></a>MSE Equation</h2><p>In the training the loss will be the Mean Square Error (MSE) equation. </p><p><img src="/2018/12/09/ml-project/images/mse.jpg"></p><h2 id="Definition-of-Total-Loss"><a href="#Definition-of-Total-Loss" class="headerlink" title="Definition of Total Loss"></a>Definition of Total Loss</h2><p><img src="/2018/12/09/ml-project/images/total.png"></p><h2 id="Training-Loss-Plot"><a href="#Training-Loss-Plot" class="headerlink" title="Training Loss Plot"></a>Training Loss Plot</h2><ul><li>The loss plot in the training progress. It only takes 4 epoches, approximately 320000 iterations.</li></ul><p><img src="/2018/12/09/ml-project/images/loss_plot.png"></p><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><ul><li><p>VGG 16 was used to extract the feature and reconstruct images.</p></li><li><p>Training the network takes very long time, a light CNN may be used for time reduction.</p></li><li><p>The tune of parameter α and β to change the output.</p></li></ul><h1 id="Demo-Video"><a href="#Demo-Video" class="headerlink" title="Demo Video"></a>Demo Video</h1><p>The real-time demo video is here:</p><p><a href="https://www.youtube.com/watch?v=5WqvDl81Cj0s">https://www.youtube.com/watch?v=5WqvDl81Cj0s</a></p><p>Or referenced the gif:</p><p><img src="/2018/12/09/ml-project/images/demo.gif"></p><h1 id="Training-Dataset"><a href="#Training-Dataset" class="headerlink" title="Training Dataset"></a>Training Dataset</h1><p>The training dataset uses the Microsoft COCO 2014 dataset.</p><p>The size of the dataset is 14GB which has 80000 images in total.</p><h1 id="GitHub-Page"><a href="#GitHub-Page" class="headerlink" title="GitHub Page"></a>GitHub Page</h1><p><a href="https://github.com/jmnie/CS539-ML-18F-Project">https://github.com/jmnie/CS539-ML-18F-Project</a></p><h1 id="Presentation-Slides"><a href="#Presentation-Slides" class="headerlink" title="Presentation Slides"></a>Presentation Slides</h1><p><a href="https://prezi.com/kxdwilsggigw/">https://prezi.com/kxdwilsggigw/</a></p>]]></content>
    
    
    <summary type="html">This webpage is the host page for the WPI CS 539 Group project 2018 Fall.</summary>
    
    
    
    
    <category term="tech" scheme="https://jmnie.github.io/tags/tech/"/>
    
    <category term="EN" scheme="https://jmnie.github.io/tags/EN/"/>
    
  </entry>
  
</feed>
